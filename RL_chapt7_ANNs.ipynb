{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of images in training set {}\".format(mnist.train.images.shape))\n",
    "print(\"No. of labels in training set {}\".format(mnist.train.labels.shape))\n",
    "print(\"No. of images in testing set {}\".format(mnist.test.images.shape))\n",
    "print(\"No. of labels in testing set {}\".format(mnist.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = mnist.train.images[41].reshape(28,28)\n",
    "plt.imshow(img1, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784]) # none = number of samples batch size passed - dynamically changes at runtime\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 10 classes to classify. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifcial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "learning_rate = 0.1\n",
    "epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_xh = tf.Variable(tf.random_normal([784, 300], stddev=0.03), name = 'w_xh')\n",
    "b_h = tf.Variable(tf.random_normal([300]), name = \"b_h\")\n",
    "\n",
    "w_hy = tf.Variable(tf.random_normal([300, 10], stddev = 0.03), name = \"w_hy\")\n",
    "b_y = tf.Variable(tf.random_normal([10]), name=\"b_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward propagation\n",
    "\n",
    "z1 = tf.add(tf.matmul(x, w_xh), b_h)\n",
    "a1 = tf.nn.relu(z1)\n",
    "z2 = tf.add(tf.matmul(a1, w_hy), b_y)\n",
    "yhat = tf.nn.softmax(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost function as cross entropy loss. \n",
    "# - also known as log loss\n",
    "# log loss = - Sum yiLog(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(yhat), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective is to minimize cost function\n",
    "# the cost function is minimized back propagating the network backward and performing gradient descent\n",
    "# tensor flows gradient descent optimiser does this...\n",
    "\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(yhat, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    total_batch = int(len(mnist.train.labels) / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run([optimiser, cross_entropy], \n",
    "                            feed_dict = {x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost=\"\"{:.3f}\".format(avg_cost))\n",
    "    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "- LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "fashion_mnist = input_data.read_data_sets('data/fashion/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images in training set (55000, 784)\n",
      "No. of labels in training set (55000, 10)\n",
      "No. of images in testing set (10000, 784)\n",
      "No. of labels in testing set (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of images in training set {}\".format(fashion_mnist.train.images.shape))\n",
    "print(\"No. of labels in training set {}\".format(fashion_mnist.train.labels.shape))\n",
    "print(\"No. of images in testing set {}\".format(fashion_mnist.test.images.shape))\n",
    "print(\"No. of labels in testing set {}\".format(fashion_mnist.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    0: \"T-shirt\", \n",
    "    1: \"Trouser\", \n",
    "    2: \"Pullover\", \n",
    "    3: \"Dress\", \n",
    "    4: \"Coat\", \n",
    "    5: \"Sandal\", \n",
    "    6: \"Shirt\", \n",
    "    7: \"Sneaker\", \n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0 (T-shirt)\n"
     ]
    }
   ],
   "source": [
    "img2 = fashion_mnist.train.images[19].reshape(28,28)\n",
    "label1 = np.where(fashion_mnist.train.labels[19] == 1)[0][0]\n",
    "print(\"y = {} ({})\".format(label1, labels[label1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb2bac2a58>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img2, cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construct CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
